{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnoIJZyUXHTA"
      },
      "source": [
        "# **Predicción de sentimientos de Análisis de Reseñas de Libros en Amazon - Utilización, procesamiento y visualización de grandes volúmenes de datos (Portafolio Análisis)**\n",
        "\n",
        "Gabriela Chimali Nava Ramírez - A01710530\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CvXAWu_j_83"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Este proyecto aborda un desafío de Big Data, analizar 3 millones de reseñas de libros de Amazon, un conjunto de datos de más de 2.6 GB. El objetivo principal es construir y evaluar un modelo de Machine Learning capaz de clasificar automáticamente el sentimiento de una reseña como \"Positivo\" (1.0) o \"Negativo\" (0.0).\n",
        "\n",
        "Para manejar este volumen de datos, todo el proceso se realiza con Apache Spark (PySpark). El cuaderno documenta el flujo de trabajo completo:\n",
        "\n",
        "1. ETL: Carga, limpieza y unión de los datos de reseñas y metadatos de los libros.\n",
        "\n",
        "2. Feature Engineering: Conversión del texto de las reseñas (NLP) y las categorías de los libros en características numéricas que el modelo pueda entender.\n",
        "\n",
        "3. Modelado: Se entrenan dos modelos, Regresión Logística y Random Forest, para comparar su rendimiento. Utilizando una técnica de ponderación de clases (weightCol) para ayudar al Random Forest a manejar el desbalance entre reseñas positivas y negativas.\n",
        "\n",
        "4. Evaluación: Se evalúan los modelos usando métricas como Precisión, Recall y F1-Score.\n",
        "\n",
        "5. Visualización: Se exportan los resultados agregados para su visualización en Tableau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5RXxBLH7iJI"
      },
      "source": [
        "## 0. Inicializar entorno PySpark y montar Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EknDcIlgYMRN"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "!pip install pyspark -q\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/usr/local/lib/python3.12/dist-packages/pyspark\"\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ProjectBigData\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr63cCy5hU3P",
        "outputId": "36892a0c-ced8-4b5a-8a64-22fed058b0b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqCZQXwGDasy"
      },
      "source": [
        "## 1. ETL inicial de los datos\n",
        "\n",
        "### 1.1. Carga de DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3XwxskD36X6",
        "outputId": "8ce5079d-5ed3-468d-af4d-22907c362586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cargando DataFrames...\n"
          ]
        }
      ],
      "source": [
        "# Rutas a los archivos\n",
        "ratings_path = \"/content/gdrive/MyDrive/AI_data_set/AmazonBooksReviews/Books_rating.csv\"\n",
        "metadata_path = \"/content/gdrive/MyDrive/AI_data_set/AmazonBooksReviews/books_data.csv\"\n",
        "\n",
        "print(\"\\nCargando DataFrames...\")\n",
        "df_ratings_raw = spark.read.csv(\n",
        "    ratings_path,\n",
        "    header=True,\n",
        "    inferSchema=True,\n",
        "    sep=',',\n",
        "    multiLine=True,\n",
        "    escape='\"'\n",
        ")\n",
        "\n",
        "df_books_raw = spark.read.csv(\n",
        "    metadata_path,\n",
        "    header=True,\n",
        "    inferSchema=True,\n",
        "    sep=',',\n",
        "    multiLine=True,\n",
        "    escape='\"'\n",
        ")\n",
        "\n",
        "# Seleccionar sólo las columnas necesarias\n",
        "df_ratings = df_ratings_raw.select(\n",
        "    col(\"Title\").alias(\"title\"),\n",
        "    col(\"review/score\").alias(\"reviewScore\"),\n",
        "    col(\"review/text\").alias(\"reviewText\")\n",
        ")\n",
        "\n",
        "df_books = df_books_raw.select(\n",
        "    col(\"Title\").alias(\"title\"),\n",
        "    \"categories\",\n",
        "    \"authors\",\n",
        "    \"publishedDate\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP4x4PCQNgZx",
        "outputId": "bde9b1ef-59e5-419a-c7fd-b909e01f697c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reseñas cargadas: 3000000\n",
            "Tamaño del archivo de reseñas: 2.66 GB\n",
            "Datos de los libros cargados: 212404\n",
            "Tamaño del archivo de datos de libros: 0.17 GB\n"
          ]
        }
      ],
      "source": [
        "def file_size(file_path):\n",
        "    size_bytes = os.path.getsize(file_path)\n",
        "    size_gb = size_bytes / (1024 * 1024 * 1024)\n",
        "    return size_gb\n",
        "\n",
        "print(f\"Reseñas cargadas: {df_ratings.count()}\")\n",
        "print(f\"Tamaño del archivo de reseñas: {file_size(ratings_path):.2f} GB\")\n",
        "print(f\"Datos de los libros cargados: {df_books.count()}\")\n",
        "print(f\"Tamaño del archivo de datos de libros: {file_size(metadata_path):.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FddciWzgOifK",
        "outputId": "cdef7e5c-9e78-4d74-9ef6-8846488ecee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Primeras 10 filas de df_ratings:\n",
            "+--------------------+-----------+--------------------+\n",
            "|               title|reviewScore|          reviewText|\n",
            "+--------------------+-----------+--------------------+\n",
            "|Its Only Art If I...|        4.0|This is only for ...|\n",
            "|Dr. Seuss: Americ...|        5.0|I don't care much...|\n",
            "|Dr. Seuss: Americ...|        5.0|If people become ...|\n",
            "|Dr. Seuss: Americ...|        4.0|Theodore Seuss Ge...|\n",
            "|Dr. Seuss: Americ...|        4.0|Philip Nel - Dr. ...|\n",
            "|Dr. Seuss: Americ...|        4.0|\"Dr. Seuss: Ameri...|\n",
            "|Dr. Seuss: Americ...|        5.0|Theodor Seuss Gie...|\n",
            "|Dr. Seuss: Americ...|        5.0|When I recieved t...|\n",
            "|Dr. Seuss: Americ...|        5.0|Trams (or any pub...|\n",
            "|Dr. Seuss: Americ...|        4.0|As far as I am aw...|\n",
            "+--------------------+-----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "Primeras 10 filas de df_books:\n",
            "+--------------------+--------------------+--------------------+-------------+\n",
            "|               title|          categories|             authors|publishedDate|\n",
            "+--------------------+--------------------+--------------------+-------------+\n",
            "|Its Only Art If I...|['Comics & Graphi...|    ['Julie Strain']|         1996|\n",
            "|Dr. Seuss: Americ...|['Biography & Aut...|      ['Philip Nel']|   2005-01-01|\n",
            "|Wonderful Worship...|        ['Religion']|    ['David R. Ray']|         2000|\n",
            "|Whispers of the W...|         ['Fiction']| ['Veronica Haddon']|      2005-02|\n",
            "|Nation Dance: Rel...|                NULL|     ['Edward Long']|   2003-03-01|\n",
            "|The Church of Chr...|        ['Religion']|['Everett Ferguson']|         1996|\n",
            "|The Overbury affa...|                NULL|['Miriam Allen De...|         1960|\n",
            "|A Walk in the Woo...|                NULL|    ['Lee Blessing']|         1988|\n",
            "|Saint Hyacinth of...|['Biography & Aut...|['Mary Fabyan Win...|   2009-01-01|\n",
            "|Rising Sons and D...|  ['Social Science']|  ['Steven Wardell']|         1995|\n",
            "+--------------------+--------------------+--------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nPrimeras 10 filas de df_ratings:\")\n",
        "df_ratings.show(10)\n",
        "\n",
        "print(\"\\nPrimeras 10 filas de df_books:\")\n",
        "df_books.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJAuITsb7K7k"
      },
      "source": [
        "### 1.2. Limpieza de los datos para el JOIN\n",
        "\n",
        "Primero se identifican los registros nulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edj5maPk4XWa",
        "outputId": "471b0ff1-7dc7-4d5e-8d2e-befb58daa4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros nulos en df_books:\n",
            "+-----+----------+-------+-------------+\n",
            "|title|categories|authors|publishedDate|\n",
            "+-----+----------+-------+-------------+\n",
            "|    1|     41199|  31413|        25305|\n",
            "+-----+----------+-------+-------------+\n",
            "\n",
            "Registros nulos en df_ratings:\n",
            "+-----+-----------+----------+\n",
            "|title|reviewScore|reviewText|\n",
            "+-----+-----------+----------+\n",
            "|  208|          0|         8|\n",
            "+-----+-----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Registros nulos en df_books:\")\n",
        "df_books.select([\n",
        "    count(when(isnull(col) | isnan(col), col)).alias(col)\n",
        "    for col in df_books.columns\n",
        "]).show()\n",
        "\n",
        "print(\"Registros nulos en df_ratings:\")\n",
        "df_ratings.select([\n",
        "    count(when(isnull(col) | isnan(col), col)).alias(col)\n",
        "    for col in df_ratings.columns\n",
        "]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDIHL6OfULBa"
      },
      "source": [
        "Se **eliminan** las filas si las columnas críticas son nulas.\n",
        "* Para ratings: `[\"Title\", \"review/score\", \"review/text\"]`\n",
        "* Para books: `[\"Title\"]`\n",
        "\n",
        "Se **imputan** los nulos de las siguientes columnas de books:\n",
        "\n",
        "`[\"categories\", \"authors\", \"publisher\"]` con la etiqueta `\"Desconocido\"`\n",
        "\n",
        "`[\"publicationDate\"]` con `0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQRJBRpwUFbv",
        "outputId": "a059a95b-d768-4824-ecdb-20685c94237f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reseñas después de limpieza: 2999784\n",
            "Books después de limpieza: 212403\n"
          ]
        }
      ],
      "source": [
        "# Eliminar filas de ratings\n",
        "columnas_criticas_ratings = [\"title\", \"reviewScore\", \"reviewText\"]\n",
        "df_ratings_clean = df_ratings.dropna(subset=columnas_criticas_ratings)\n",
        "\n",
        "# Eliminar filas de books si \"Title\" es nulo\n",
        "df_books_clean = df_books.dropna(subset=[\"title\"])\n",
        "\n",
        "# Imputar features nulos en books\n",
        "columnas_imputar = [\"categories\", \"authors\"]\n",
        "df_books_clean = df_books_clean.fillna(\"Desconocido\", subset=columnas_imputar)\n",
        "\n",
        "df_books_clean = df_books_clean.withColumn(\n",
        "    \"publicationYear\",\n",
        "    substring(col(\"publishedDate\"), 1, 4).cast(IntegerType())\n",
        ")\n",
        "# Imputar años nulos o mal formados con 0 en books\n",
        "df_books_clean = df_books_clean.fillna(0, subset=[\"publicationYear\"])\n",
        "df_books_clean = df_books_clean.drop(\"publishedDate\")\n",
        "\n",
        "print(f\"Reseñas después de limpieza: {df_ratings_clean.count()}\")\n",
        "print(f\"Books después de limpieza: {df_books_clean.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "djC0ZL9PXinr"
      },
      "outputs": [],
      "source": [
        "df_books_clean = df_books_clean.withColumn(\n",
        "    \"title\",\n",
        "    trim(regexp_replace(lower(col(\"title\")), r\"[^a-z0-9\\s]\", \"\"))\n",
        ")\n",
        "\n",
        "df_ratings_clean = df_ratings_clean.withColumn(\n",
        "    \"title\",\n",
        "    trim(regexp_replace(lower(col(\"title\")), r\"[^a-z0-9\\s]\", \"\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfT5GU_Qgr6G",
        "outputId": "00aac606-1de6-43fe-d051-bde65539f8b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+---------------+\n",
            "|               title|          categories|             authors|publicationYear|\n",
            "+--------------------+--------------------+--------------------+---------------+\n",
            "|its only art if i...|['Comics & Graphi...|    ['Julie Strain']|           1996|\n",
            "|dr seuss american...|['Biography & Aut...|      ['Philip Nel']|           2005|\n",
            "|wonderful worship...|        ['Religion']|    ['David R. Ray']|           2000|\n",
            "|whispers of the w...|         ['Fiction']| ['Veronica Haddon']|           2005|\n",
            "|nation dance reli...|         Desconocido|     ['Edward Long']|           2003|\n",
            "|the church of chr...|        ['Religion']|['Everett Ferguson']|           1996|\n",
            "|the overbury affa...|         Desconocido|['Miriam Allen De...|           1960|\n",
            "|a walk in the woo...|         Desconocido|    ['Lee Blessing']|           1988|\n",
            "|saint hyacinth of...|['Biography & Aut...|['Mary Fabyan Win...|           2009|\n",
            "|rising sons and d...|  ['Social Science']|  ['Steven Wardell']|           1995|\n",
            "+--------------------+--------------------+--------------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+--------------------+-----------+--------------------+\n",
            "|               title|reviewScore|          reviewText|\n",
            "+--------------------+-----------+--------------------+\n",
            "|its only art if i...|        4.0|This is only for ...|\n",
            "|dr seuss american...|        5.0|I don't care much...|\n",
            "|dr seuss american...|        5.0|If people become ...|\n",
            "|dr seuss american...|        4.0|Theodore Seuss Ge...|\n",
            "|dr seuss american...|        4.0|Philip Nel - Dr. ...|\n",
            "|dr seuss american...|        4.0|\"Dr. Seuss: Ameri...|\n",
            "|dr seuss american...|        5.0|Theodor Seuss Gie...|\n",
            "|dr seuss american...|        5.0|When I recieved t...|\n",
            "|dr seuss american...|        5.0|Trams (or any pub...|\n",
            "|dr seuss american...|        4.0|As far as I am aw...|\n",
            "+--------------------+-----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_books_clean.show(10)\n",
        "df_ratings_clean.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY174cSHCPcK",
        "outputId": "55ed5d18-3f9c-4683-9b88-d82fae6fb2b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Books después de borrar duplicados: 207065\n"
          ]
        }
      ],
      "source": [
        "df_books_clean = df_books_clean.dropDuplicates([\"title\"])\n",
        "print(f\"Books después de borrar duplicados: {df_books_clean.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2wQCoHPIailc"
      },
      "outputs": [],
      "source": [
        "df_join = df_ratings_clean.join(\n",
        "    df_books_clean,\n",
        "    on=\"title\",\n",
        "    how=\"left\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6xZR1eLjxlK",
        "outputId": "eb6bdf37-831e-4eac-ecbc-9af3dd7c422e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros nulos en df_join:\n",
            "+-----+-----------+----------+----------+-------+---------------+\n",
            "|title|reviewScore|reviewText|categories|authors|publicationYear|\n",
            "+-----+-----------+----------+----------+-------+---------------+\n",
            "|    0|          0|         0|         0|      0|              0|\n",
            "+-----+-----------+----------+----------+-------+---------------+\n",
            "\n",
            "Reseñas después del join: 2999784\n"
          ]
        }
      ],
      "source": [
        "print(\"Registros nulos en df_join:\")\n",
        "df_join.select([\n",
        "    count(when(isnull(col) | isnan(col), col)).alias(col)\n",
        "    for col in df_join.columns\n",
        "]).show()\n",
        "\n",
        "print(f\"Reseñas después del join: {df_join.count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae1BPzoAI5JY"
      },
      "source": [
        "### 1.3. Creación de la Etiqueta para el modelo\n",
        "\n",
        "Usando reviewScore\n",
        "\n",
        "Ignorar reseñas de 3 estrellas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhUNwyS9IHrR",
        "outputId": "ea0b871c-254d-4b91-b5ba-331ef8c18e46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas para el modelo (sin 3 estrellas): 2745497\n"
          ]
        }
      ],
      "source": [
        "df_labeled = df_join.withColumn(\"label\",\n",
        "    when(col(\"reviewScore\") >= 4.0, 1.0)\n",
        "    .when(col(\"reviewScore\") <= 2.0, 0.0)\n",
        "    .otherwise(None)\n",
        ")\n",
        "\n",
        "df_model_data = df_labeled.dropna(subset=[\"label\"])\n",
        "print(f\"Filas para el modelo (sin 3 estrellas): {df_model_data.count()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isK5QjgzQYor"
      },
      "source": [
        "### 1.4. Limpieza de cadenas de texto\n",
        "\n",
        "Si hay más de una categoría o autor ligado al libro se **queda** sólo la/el primer nombre registrado en la fila."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtRMSV0fON16",
        "outputId": "0e351c6d-15c1-4f56-c758-d459e0334fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+--------------------+--------------------+----------+---------------+-----+\n",
            "|               title|reviewScore|          reviewText|          categories|   authors|publicationYear|label|\n",
            "+--------------------+-----------+--------------------+--------------------+----------+---------------+-----+\n",
            "|dr seuss american...|        5.0|I don't care much...|Biography & Autob...|Philip Nel|           2005|  1.0|\n",
            "|dr seuss american...|        5.0|If people become ...|Biography & Autob...|Philip Nel|           2005|  1.0|\n",
            "|dr seuss american...|        4.0|Theodore Seuss Ge...|Biography & Autob...|Philip Nel|           2005|  1.0|\n",
            "|dr seuss american...|        4.0|Philip Nel - Dr. ...|Biography & Autob...|Philip Nel|           2005|  1.0|\n",
            "|dr seuss american...|        4.0|\"Dr. Seuss: Ameri...|Biography & Autob...|Philip Nel|           2005|  1.0|\n",
            "+--------------------+-----------+--------------------+--------------------+----------+---------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Limpiar y obtener la primera categoría\n",
        "df_model_data = df_model_data.withColumn(\"categories\",\n",
        "    regexp_replace(col(\"categories\"), r\"[\\'\\[\\]]\", \"\")\n",
        ")\n",
        "df_model_data = df_model_data.withColumn(\"categories\",\n",
        "    split(col(\"categories\"), \",\")[0]\n",
        ")\n",
        "\n",
        "# Limpiar y obtener el primer autor\n",
        "df_model_data = df_model_data.withColumn(\"authors\",\n",
        "    regexp_replace(col(\"authors\"), r\"[\\'\\[\\]]\", \"\")\n",
        ")\n",
        "df_model_data = df_model_data.withColumn(\"authors\",\n",
        "    split(col(\"authors\"), \",\")[0]\n",
        ")\n",
        "\n",
        "df_model_data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIRuJc5UWetz",
        "outputId": "ce49793d-5fa3-4f6b-efba-c451d5ce165b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Total de filas con strings limpios: 2745497\n"
          ]
        }
      ],
      "source": [
        "df_complete = df_model_data.select(\n",
        "    \"label\",\n",
        "    \"reviewText\",\n",
        "    col (\"categories\").alias (\"category\"),\n",
        "    col(\"authors\").alias (\"first_author\"),\n",
        "    \"publicationYear\"\n",
        ")\n",
        "\n",
        "df_complete_clean = df_complete.dropna()\n",
        "\n",
        "print(f\">> Total de filas con strings limpios: {df_complete_clean.count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4yasVCVhAp1"
      },
      "source": [
        "### 1.5. Seleccionar sólo las categorías más representativas\n",
        "\n",
        "1. Calcular cantidad de reseñas.\n",
        "2. Calcular cantidad de reseñas por categoría y su equivalencia en porcentaje respecto al total.\n",
        "3. Seleccionar sólo las categorías que representan más del 1% del total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2b4dfa",
        "outputId": "ab8f43e6-4310-4568-aab6-364f2504ba3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorías que representan más del 1% del total de reseñas:\n",
            "['Computers', 'Social Science', 'Biography & Autobiography', 'Business & Economics', 'Religion', 'Fiction', 'History', 'Juvenile Nonfiction', 'Self-Help', 'Juvenile Fiction', 'Desconocido', 'Cooking']\n",
            "\n",
            ">> Filas después de filtrar por categorías (> 1%): 1922939\n"
          ]
        }
      ],
      "source": [
        "total_reviews = df_complete_clean.count()\n",
        "\n",
        "df_category_counts = df_complete_clean.groupBy(\"category\").count()\n",
        "df_category_counts = df_category_counts.withColumn(\n",
        "    \"percentage\",\n",
        "    (col(\"count\") / total_reviews) * 100\n",
        ")\n",
        "\n",
        "categories_to_keep = [row[\"category\"] for row in df_category_counts.filter(col(\"percentage\") > 1).collect()]\n",
        "\n",
        "print(\"Categorías que representan más del 1% del total de reseñas:\")\n",
        "print(categories_to_keep)\n",
        "\n",
        "df_filtered = df_complete_clean.filter(col(\"category\").isin(categories_to_keep))\n",
        "\n",
        "print(f\"\\n>> Filas después de filtrar por categorías (> 1%): {df_filtered.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-_vbXkLm5nK",
        "outputId": "367cc2b8-c2ab-405d-8509-4542011108ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivo limpio guardado en: /content/gdrive/MyDrive/AI_data_set/AmazonBooksReviews/df_clean.csv\n"
          ]
        }
      ],
      "source": [
        "path_clean = \"/content/gdrive/MyDrive/AI_data_set/AmazonBooksReviews/df_clean.csv\"\n",
        "df_filtered.coalesce(1).write.csv(path_clean, header=True, mode=\"overwrite\")\n",
        "print(f\"Archivo limpio guardado en: {path_clean}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjjMLR3kYkfI"
      },
      "source": [
        "## 2. Feature Engineering\n",
        "\n",
        "### 2.1. Importar librerías y división de datos\n",
        "\n",
        "Separar los conjuntos de entrenamiento (80%) y prueba (20%).\n",
        "\n",
        "Se guardarán en el caché para un acceso más rápido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHTMUDM3YsMf",
        "outputId": "2707df49-897c-4e5f-d1aa-6aee86712709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[label: double, reviewText: string, category: string, first_author: string, publicationYear: int]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import (\n",
        "    Tokenizer, StopWordsRemover, HashingTF, IDF,\n",
        "    StringIndexer, OneHotEncoder, VectorAssembler\n",
        ")\n",
        "\n",
        "(train, test) = df_filtered.randomSplit([0.8, 0.2], seed=42)\n",
        "train.cache()\n",
        "test.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0trV741BcFMJ"
      },
      "source": [
        "\n",
        "### 2.2. Procesamiento de Texto (NLP)\n",
        "\n",
        "* Tokenizar: Separar el texto en palabras.\n",
        "\n",
        "* StopWordsRemover: Eliminar palabras comunes que no aportan al modelo. Como \"el\", \"la\", \"y\".\n",
        "\n",
        "* HashingTF: Convertir las palabras en un vector de números."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pZQlgOmYcLNa"
      },
      "outputs": [],
      "source": [
        "tokenizer_text = Tokenizer(inputCol=\"reviewText\", outputCol=\"words_text\")\n",
        "stopwords_text = StopWordsRemover(inputCol=\"words_text\", outputCol=\"filtered_text\")\n",
        "hashingtf_text = HashingTF(inputCol=\"filtered_text\", outputCol=\"features_text\", numFeatures=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvXN6fpodj44"
      },
      "source": [
        "### 2.3. Procesamiento de variables categóricas\n",
        "\n",
        "* StringIndexer: Convierte las categorías en un número.\n",
        "\n",
        "* OneHotEncoder: Convierte en un vector de 1's y 0's ls indices anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LNPhT7xJdi7z"
      },
      "outputs": [],
      "source": [
        "index_category = StringIndexer(inputCol=\"category\", outputCol=\"category_index\", handleInvalid=\"keep\")\n",
        "ohe_category = OneHotEncoder(inputCol=\"category_index\", outputCol=\"category_vec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqLVir_ne4Af"
      },
      "source": [
        "### 2.4. Ensamblar todas las features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1lAAv93xe9xM"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"features_text\",\n",
        "        \"category_vec\",\n",
        "        \"publicationYear\"\n",
        "    ],\n",
        "    outputCol=\"features\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjFz-ER5f1WZ"
      },
      "source": [
        "## 3. Modelado\n",
        "\n",
        "### 3.1. Definir modelo y pipelines\n",
        "\n",
        "Para el RandomForest se designan manualmente los pesos de las clases dado que nos encontramos con un desbalance significativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mLcyM0X2geDu"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import (\n",
        "    LogisticRegression, RandomForestClassifier\n",
        ")\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "# Modelo 1: Regresión Logística\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Modelo 2: Random Forest\n",
        "class_weights = {1.0: 1.0, 0.0: 6.0}\n",
        "\n",
        "# Agregar columna de \"weight\" al DataFrame\n",
        "df_weighted = df_filtered.withColumn(\"weight\", when(col(\"label\") == 1.0, class_weights[1.0]).otherwise(class_weights[0.0]))\n",
        "\n",
        "# Separación de conjuntos\n",
        "(train_weighted, test_weighted) = df_weighted.randomSplit([0.8, 0.2], seed=42)\n",
        "train_weighted.cache()\n",
        "test_weighted.cache()\n",
        "\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42, weightCol=\"weight\")\n",
        "\n",
        "# --- Pipeline 1: Con Regresión Logística ---\n",
        "pipeline_lr = Pipeline(stages=[\n",
        "    tokenizer_text, stopwords_text, hashingtf_text,\n",
        "    index_category, ohe_category,\n",
        "    assembler,\n",
        "    lr\n",
        "])\n",
        "\n",
        "# --- Pipeline 2: Con Random Forest ---\n",
        "pipeline_rf = Pipeline(stages=[\n",
        "    tokenizer_text, stopwords_text, hashingtf_text,\n",
        "    index_category, ohe_category,\n",
        "    assembler,\n",
        "    rf\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYqJtNaxhqnv"
      },
      "source": [
        "### 3.2. Entrenamiento de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yes3b14W-nNH",
        "outputId": "6c6fc0d5-ef3a-460b-e7c6-74fd3ea631af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando Modelo 1: Regresión Lineal\n"
          ]
        }
      ],
      "source": [
        "print(\"Entrenando Modelo 1: Regresión Lineal\")\n",
        "model_lr = pipeline_lr.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6Jl05Wftqpd",
        "outputId": "602e1390-fce6-414f-e3b8-01e65649fd75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando Modelo 2: Random Forest\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEntrenando Modelo 2: Random Forest\")\n",
        "model_rf = pipeline_rf.fit(train_weighted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3. Generar predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9OKZfSygohF",
        "outputId": "e8fe676c-f4fd-4d11-cf8f-08e4621500ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicciones Modelo 1: Regresión Logística\n",
            "Predicciones Modelo 2: Random Forest\n"
          ]
        }
      ],
      "source": [
        "print(\"Predicciones Modelo 1: Regresión Logística\")\n",
        "predictions_lr = model_lr.transform(test)\n",
        "print(\"Predicciones Modelo 2: Random Forest\")\n",
        "predictions_rf = model_rf.transform(test_weighted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njq1JsYhgeBi"
      },
      "source": [
        "## 4. Evaluación de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdvqQQOSgdB2",
        "outputId": "12eb5dbb-e25e-4fa0-b839-b31d139b1100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Evaluación Regresión Logística\n",
            "Accuracy (LR): 0.8814\n",
            "F1-Score (LR): 0.8525\n",
            "Precision (para Negativos) (LR): 0.6397\n",
            "Recall (para Positivos) (LR): 0.9838\n",
            "\n",
            "Matriz de Confusión (LR):\n",
            "+-----+----------+------+\n",
            "|label|prediction| count|\n",
            "+-----+----------+------+\n",
            "|  0.0|       0.0|  9625|\n",
            "|  0.0|       1.0| 40234|\n",
            "|  1.0|       0.0|  5420|\n",
            "|  1.0|       1.0|329689|\n",
            "+-----+----------+------+\n",
            "\n",
            "\n",
            ">> Evaluación Random Forest\n",
            "Accuracy (RF): 0.8350\n",
            "F1-Score (RF): 0.8301\n",
            "Precision (para Negativos) (RF): 0.3426\n",
            "Recall (para Positivos) (RF): 0.9149\n",
            "\n",
            "Matriz de Confusión (RF):\n",
            "+-----+----------+------+\n",
            "|label|prediction| count|\n",
            "+-----+----------+------+\n",
            "|  0.0|       0.0| 14864|\n",
            "|  0.0|       1.0| 34995|\n",
            "|  1.0|       0.0| 28525|\n",
            "|  1.0|       1.0|306584|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import col, sum, when\n",
        "\n",
        "print(\">> Evaluación Regresión Logística\")\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "acc_lr = evaluator.setMetricName(\"accuracy\").evaluate(predictions_lr)\n",
        "print(f\"Accuracy (LR): {acc_lr:.4f}\")\n",
        "\n",
        "f1_lr = evaluator.setMetricName(\"f1\").evaluate(predictions_lr)\n",
        "print(f\"F1-Score (LR): {f1_lr:.4f}\")\n",
        "\n",
        "prec_lr = evaluator.setMetricName(\"precisionByLabel\").setMetricLabel(0.0).evaluate(predictions_lr)\n",
        "print(f\"Precision (para Negativos) (LR): {prec_lr:.4f}\")\n",
        "\n",
        "recall_lr = evaluator.setMetricName(\"recallByLabel\").setMetricLabel(1.0).evaluate(predictions_lr)\n",
        "print(f\"Recall (para Positivos) (LR): {recall_lr:.4f}\")\n",
        "\n",
        "print(\"\\nMatriz de Confusión (LR):\")\n",
        "confusion_matrix_lr = predictions_lr.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\")\n",
        "confusion_matrix_lr.show()\n",
        "\n",
        "print(\"\\n>> Evaluación Random Forest\")\n",
        "\n",
        "acc_rf = evaluator.setMetricName(\"accuracy\").evaluate(predictions_rf)\n",
        "print(f\"Accuracy (RF): {acc_rf:.4f}\")\n",
        "\n",
        "f1_rf = evaluator.setMetricName(\"f1\").evaluate(predictions_rf)\n",
        "print(f\"F1-Score (RF): {f1_rf:.4f}\")\n",
        "\n",
        "prec_rf = evaluator.setMetricName(\"precisionByLabel\").setMetricLabel(0.0).evaluate(predictions_rf)\n",
        "print(f\"Precision (para Negativos) (RF): {prec_rf:.4f}\")\n",
        "\n",
        "recall_rf = evaluator.setMetricName(\"recallByLabel\").setMetricLabel(1.0).evaluate(predictions_rf)\n",
        "print(f\"Recall (para Positivos) (RF): {recall_rf:.4f}\")\n",
        "\n",
        "print(\"\\nMatriz de Confusión (RF):\")\n",
        "confusion_matrix_rf = predictions_rf.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\")\n",
        "confusion_matrix_rf.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TqjWWbYhR7L"
      },
      "source": [
        "## 5. Visualización\n",
        "\n",
        "### 5.1. Exportación de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYy3eblrZkMK",
        "outputId": "18fd0acc-508b-44f0-cc71-5bbb108bd06c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exportando CSVs para Tableau...\n",
            "Archivo de Categorías guardado en: /content/gdrive/MyDrive/AI_data_set/AmazonBooksReviews/tableau_category.csv\n",
            "Archivo de Autores guardado en: /content/gdrive/MyDrive/AI_data_set/AmazonBooksReviews/tableau_autor.csv\n"
          ]
        }
      ],
      "source": [
        "def aggregate_model_performance(predictions_df, model_name, group_by_col):\n",
        "\n",
        "    df_agg = predictions_df.groupBy(group_by_col) \\\n",
        "        .agg(\n",
        "            count(\"*\").alias(\"total_de_reseñas\"),\n",
        "            sum(when(col(\"label\") == 1.0, 1).otherwise(0)).alias(\"positivo_real\"),\n",
        "            sum(when(col(\"label\") == 0.0, 1).otherwise(0)).alias(\"negativo_real\"),\n",
        "            sum(when(col(\"prediction\") == 1.0, 1).otherwise(0)).alias(\"positivo_predicho\"),\n",
        "            sum(when(col(\"prediction\") == 0.0, 1).otherwise(0)).alias(\"negativo_predicho\")\n",
        "        ) \\\n",
        "        .withColumn(\"model_name\", lit(model_name))\n",
        "\n",
        "    return df_agg\n",
        "\n",
        "agg_lr_cat = aggregate_model_performance(predictions_lr, \"Regresión Logística\", \"category\")\n",
        "agg_rf_cat = aggregate_model_performance(predictions_rf, \"Random Forest\", \"category\")\n",
        "\n",
        "df_comparacion_categoria = agg_lr_cat.union(agg_rf_cat)\n",
        "\n",
        "agg_lr_auth = aggregate_model_performance(predictions_lr, \"Regresión Logística\", \"first_author\")\n",
        "agg_rf_auth = aggregate_model_performance(predictions_rf, \"Random Forest\", \"first_author\")\n",
        "\n",
        "df_comparacion_autor = agg_lr_auth.union(agg_rf_auth)\n",
        "\n",
        "print(\"Exportando CSVs para Tableau...\")\n",
        "path_cat = \"/content/gdrive/MyDrive/AI_data_set/AmazonBooksReviews/tableau_category.csv\"\n",
        "path_auth = \"/content/gdrive/MyDrive/AI_data_set/AmazonBooksReviews/tableau_autor.csv\"\n",
        "\n",
        "# Exportar directamente a CSV usando PySpark\n",
        "df_comparacion_categoria.coalesce(1).write.csv(path_cat, header=True, mode=\"overwrite\")\n",
        "print(f\"Archivo de Categorías guardado en: {path_cat}\")\n",
        "\n",
        "df_comparacion_autor.coalesce(1).write.csv(path_auth, header=True, mode=\"overwrite\")\n",
        "print(f\"Archivo de Autores guardado en: {path_auth}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKLRuG6mqc1"
      },
      "source": [
        "## Conclusiones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ag4PmETO2NB"
      },
      "source": [
        "## Referencias\n",
        "\n",
        "1.  Bekheet, M. (2022, septiembre 13). *Amazon Books Reviews*. https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews/data\n",
        "2. Sharma, S. (2023, diciembre 28). *Amazon Books Review (EDA + Sentiment-Analysis)*. https://www.kaggle.com/code/shubham2703/amazon-books-review-eda-sentiment-analysis\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
